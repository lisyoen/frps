# frps 프로젝트 지시사항

## 프로젝트 개요
- **프로젝트 경로**: `D:\git\frps\`
- **목적**: HTTP 터널 시스템 개발 (회사 내부망 LLM 서버 외부 접근)
- **주요 파일**: 
  - `tunnel-server/tunnel_server.py` (MiniPC)
  - `tunnel-client/tunnel_client.py` (SubPC, 회사)

## 개발 환경

### MainPC (현재 장비, Windows 11, 192.168.50.102)
- Node.js 22.20.0, Python 3.11.8
- **Ollama LLM 서버**: http://localhost:11434/v1
  - 모델: qwen3-coder:30b (코딩 전문 + Tool Calling 지원)
  - API Key: ollama (아무 문자열)
  - 항상 가동 중, 로컬 테스트용

### MiniPC (Linux Mint 22, 192.168.50.196)
- Node.js 20.19.1, Python 3.12.3, Docker 사용 가능
- **터널 서버 가동**: tunnel-server/tunnel_server.py (ports 8089, 8091)

### 집 환경 테스트 흐름
```
MainPC (클라이언트 개발)
    ↓ HTTP 요청
MiniPC:8091 (터널 서버)
    ↓ 터널 relay
MainPC:11434 (Ollama LLM)
```

## 서버 가동 규칙 (중요!) ⚠️

### MiniPC 터널 서버 제어
- **직접 제어 가능**: MiniPC에 SSH Remote로 직접 접속했을 때만
- **제어 불가**: MainPC에서 작업 중일 때
  - ❌ MainPC에서 MiniPC 서버를 원격으로 시작/중지 금지
  - ✅ 사용자에게 "MiniPC 터널 서버를 시작해주세요" 요청

### MainPC Ollama 서버
- 항상 가동 중 (http://localhost:11434/v1)
- 로컬 테스트용으로 자유롭게 활용

## Tool 사용 원칙

### 실행 가능한 질문은 반드시 도구 사용
사용자가 실행 가능한 작업을 요청할 때는 **반드시 도구를 사용해서 실행**합니다.

**도구 사용이 필요한 경우:**
- 파일 시스템 정보 조회
- 시스템 정보 확인
- 코드 실행 및 결과 확인
- 파일 읽기/쓰기/수정
- Git 작업
- 빌드/테스트 실행

**원칙:**
1. **실행 가능하면 → 도구 사용**
2. 설명만 필요하면 → 답변만
3. 애매하면 → 도구 사용 (더 안전)

## 최근 작업

### ✅ 터널 서버 구현 완료 (session-20251112-001)
- MiniPC에서 asyncio 기반 HTTP 터널 서버 구현
- 커맨드 채널 (8089), 데이터 채널 (8091)
- IP 기반 클라이언트 매칭
- 양방향 TCP relay
- 로컬 테스트 성공

### ✅ 터널 클라이언트 구현 완료 (session-20251112-002)
- **터널 클라이언트 개발** (MainPC, Windows 11)
- HTTP CONNECT 프록시 연결 지원
- MiniPC와 로컬 네트워크 통합 테스트 성공
- MainPC Ollama를 대상 서버로 end-to-end 검증 완료

### 🎯 다음 단계
- SubPC(회사)에 배포
- 회사 프록시 경유 테스트
- Windows/systemd 서비스 등록
